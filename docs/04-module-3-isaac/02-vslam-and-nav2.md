# 4.2 VSLAM & Nav2 ğŸ“ğŸ§­

VSLAM (Visual Simultaneous Localization and Mapping) allows robots to **map environments using cameras**.

Nav2 in ROS 2 enables **autonomous navigation** with path planning, obstacle avoidance, and goal-reaching.

---

# ğŸŒŸ Why VSLAM + Nav2?

* Robots can navigate **unknown environments** without pre-built maps ğŸ—ºï¸
* Cameras provide rich visual data ğŸŒˆ
* Works in dynamic environments with moving obstacles ğŸš¶â€â™‚ï¸ğŸš—

---

# ğŸ” VSLAM Workflow

1. Capture images from RGB or RGB-D cameras ğŸ“·
2. Extract features (ORB, SIFT, SURF) âœ¨
3. Track feature points frame-to-frame ğŸ”„
4. Estimate camera pose (position + orientation) ğŸ§­
5. Build map incrementally while localizing

---

# ğŸ› ï¸ Nav2 Overview

Nav2 provides:

* Global planner â†’ computes path to goal ğŸ—ºï¸
* Local planner â†’ avoids obstacles in real-time ğŸš§
* Recovery behaviors â†’ handles robot getting stuck ğŸ”„
* Lifecycle management â†’ manages states of navigation nodes âš¡

---

# ğŸš€ Example: Launching Nav2 in ROS 2

```bash
# Launch Nav2 with TurtleBot3
ros2 launch nav2_bringup tb3_simulation_launch.py
```

---

# ğŸ§  Integrating VSLAM with Nav2

* VSLAM publishes `/odom` and `/map` topics
* Nav2 subscribes to `/map` and `/scan` for planning
* Robot can navigate using visual input and LiDAR combined

---

# ğŸ¯ Summary

âœ” VSLAM enables mapping with cameras
âœ” Nav2 handles navigation and obstacle avoidance
âœ” Integration allows fully autonomous robot movement in simulation and real world
